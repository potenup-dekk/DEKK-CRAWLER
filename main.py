import os
import time
from datetime import datetime
from core.state_manager import StateManager
from core.delivery import send_to_sqs, send_to_batch_api
from crawlers.musinsa import MusinsaCrawler

def main():
    print(f"\nğŸš€ [{datetime.now()}] í¬ë¡¤ë§ ì›Œì»¤ ì‹¤í–‰ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    today_str = datetime.now().strftime('%Y/%m/%d')
    state_manager = StateManager('/app/data/crawler_state.json')
    
    active_crawlers = [
        MusinsaCrawler()
    ]
    
    all_processed_dtos = []
    
    for crawler in active_crawlers:
        platform = crawler.platform_name
        last_id = state_manager.get_last_id(platform)
        
        new_snap_ids = crawler.fetch_new_snaps(last_id)
        print(f"ì´ {len(new_snap_ids)}ê°œì˜ ì‹ ê·œ ìŠ¤ëƒ…ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        
        for snap_id in new_snap_ids:
            try:
                dto = crawler.process_and_upload(snap_id, today_str)
                all_processed_dtos.append(dto)
                
                state_manager.update_last_id(platform, snap_id)
                time.sleep(1) # ì°¨ë‹¨ ë°©ì§€ ë§¤ë„ˆ ë”œë ˆì´
            except Exception as e:
                print(f"âŒ {platform} ìŠ¤ëƒ…({snap_id}) ì²˜ë¦¬ ì—ëŸ¬: {e}")

    if all_processed_dtos:
        delivery_mode = os.getenv('DELIVERY_MODE', 'SQS').upper()
        print(f"\nğŸ“¦ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ. [{delivery_mode}] ë°©ì‹ìœ¼ë¡œ ì „ì†¡ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        if delivery_mode == 'BATCH':
            send_to_batch_api(all_processed_dtos)
        elif delivery_mode == 'SQS':
            send_to_sqs(all_processed_dtos)
        else:
            print(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” DELIVERY_MODE: {delivery_mode}")

if __name__ == "__main__":
    main()